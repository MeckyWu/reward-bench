{
  "random_max": {
    "win_rate": 27.313672263048893,
    "standard_error": 1.3995157220976866,
    "mode": "community",
    "avg_length": 1046,
    "n_wins": 214,
    "n_wins_base": 588,
    "n_draws": 3,
    "n_total": 805,
    "discrete_win_rate": 26.77018633540373,
    "length_controlled_winrate": 32.25897556379437,
    "reward_model": "allenai/tulu-2-dpo-13b.0"
  },
  "random_min": {
    "win_rate": 35.454792345804684,
    "standard_error": 1.4820594070973518,
    "mode": "community",
    "avg_length": 1511,
    "n_wins": 275,
    "n_wins_base": 525,
    "n_draws": 5,
    "n_total": 805,
    "discrete_win_rate": 34.47204968944099,
    "length_controlled_winrate": 29.243005028109515,
    "reward_model": "allenai/tulu-2-dpo-13b.10"
  },
  "random_median": {
    "win_rate": 31.250584896994063,
    "standard_error": 1.428759690444108,
    "mode": "community",
    "avg_length": 1234,
    "n_wins": 236,
    "n_wins_base": 565,
    "n_draws": 4,
    "n_total": 805,
    "discrete_win_rate": 29.565217391304348,
    "length_controlled_winrate": 31.13244635418687,
    "reward_model": "allenai/tulu-2-dpo-13b.3"
  },
  "openbmb/UltraRM-13b": {
    "win_rate": 49.102596740347835,
    "standard_error": 1.5287737633448522,
    "n_wins": 391,
    "n_wins_base": 411,
    "n_draws": 3,
    "n_total": 805,
    "discrete_win_rate": 48.75776397515528,
    "mode": "community",
    "avg_length": 1695,
    "length_controlled_winrate": 39.733695208233215,
    "reward_model": "openbmb/UltraRM-13b"
  },
  "weqweasdas/hh_rlhf_rm_open_llama_3b": {
    "win_rate": 38.16397599469565,
    "standard_error": 1.4896950610758206,
    "n_wins": 297,
    "n_wins_base": 504,
    "n_draws": 4,
    "n_total": 805,
    "discrete_win_rate": 37.142857142857146,
    "mode": "community",
    "avg_length": 2008,
    "length_controlled_winrate": 30.47111943294496,
    "reward_model": "weqweasdas/hh_rlhf_rm_open_llama_3b"
  },
  "PKU-Alignment/beaver-7b-v1.0-cost": {
    "win_rate": 35.84747943706833,
    "standard_error": 1.489303598585604,
    "n_wins": 281,
    "n_wins_base": 522,
    "n_draws": 2,
    "n_total": 805,
    "discrete_win_rate": 35.03105590062112,
    "mode": "community",
    "avg_length": 1640,
    "length_controlled_winrate": 31.038538771017315,
    "reward_model": "PKU-Alignment/beaver-7b-v1.0-cost"
  },
  "PKU-Alignment/beaver-7b-v1.0-reward": {
    "win_rate": 36.182010389788815,
    "standard_error": 1.4886851696808068,
    "n_wins": 280,
    "n_wins_base": 523,
    "n_draws": 2,
    "n_total": 805,
    "discrete_win_rate": 34.90683229813665,
    "mode": "community",
    "avg_length": 1915,
    "length_controlled_winrate": 28.452492042088934,
    "reward_model": "PKU-Alignment/beaver-7b-v1.0-reward"
  },
  "OpenAssistant/oasst-rm-2.1-pythia-1.4b-epoch-2.5": {
    "win_rate": 38.242602282882,
    "standard_error": 1.4844096057906566,
    "n_wins": 304,
    "n_wins_base": 496,
    "n_draws": 5,
    "n_total": 805,
    "discrete_win_rate": 38.07453416149068,
    "mode": "community",
    "avg_length": 1520,
    "length_controlled_winrate": 32.12716575776289,
    "reward_model": "OpenAssistant/oasst-rm-2.1-pythia-1.4b-epoch-2.5"
  },
  "OpenAssistant/reward-model-deberta-v3-large-v2": {
    "win_rate": 33.38721039081988,
    "standard_error": 1.459457517325159,
    "n_wins": 256,
    "n_wins_base": 546,
    "n_draws": 3,
    "n_total": 805,
    "discrete_win_rate": 31.987577639751553,
    "mode": "community",
    "avg_length": 1429,
    "length_controlled_winrate": 29.565572857922067,
    "reward_model": "OpenAssistant/reward-model-deberta-v3-large-v2"
  }
}